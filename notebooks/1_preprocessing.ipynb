{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Intertrial Variability: 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(1, '../')\n",
    "from scripts.preproc import load_prepare_data, epoch_clean\n",
    "import os\n",
    "import pickle as pkl\n",
    "from scripts.util import custom_logger, concatenate_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Define Preprocessing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and Names\n",
    "data_pth = 'D:/data/Psychiatrie_Autismus_2012/'\n",
    "folders = ['Neurotypicals', 'Asperger']\n",
    "file_codes = ['PL', 'PS']\n",
    "group_name = ['control', 'asd']\n",
    "\n",
    "# Trigger-specific Variables\n",
    "triglens = [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 21, 22, 23, 24, 25, 26, 27, 70]\n",
    "triglabels = [[10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 30], \n",
    "              [40, 40, 40, 40, 40, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 60]]\n",
    "stimuli = [['SF', 'LR', 'GPL'], ['SR', 'LF', 'GPS']]  # Codes {S: Small, L: Large, F: Frequent, R: Rare}\n",
    "round_to = 1\n",
    "onoff = [3, 3]\n",
    "\n",
    "# Preprocessing Parameters\n",
    "baseline = None  # No Baseline Correction\n",
    "trial_time = (-0.2, 0.5)  # Trial time span specification\n",
    "filtfreq = [1, 30]  # Band-pass frequencies\n",
    "rereference = ['TP9', 'TP10']  # Reference Channels\n",
    "art_thresh = None  # Artifact Threshold\n",
    "srate = 500  # Sampling rate to resample to\n",
    "rm_bad_chans = False  # No custom Bad Channel Detection\n",
    "use_ransac=True  # use RANSAC Bad Channel Detection\n",
    "csd = False  # Don't Use Current Source Density\n",
    "perform_ICA = True  # Calculate ICA and Remove Blink-related Artifacts\n",
    "n_jobs = -1  # Number of Cores to Utilize During Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load, preprocess and epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data_raw = {} \n",
    "all_data_epoch = {}\n",
    "\n",
    "subject_list = [[n for n in os.listdir(os.path.join(data_pth,folder)) if not n.startswith('.') \n",
    "                if not n.endswith('.txt')] for folder in folders]\n",
    "\n",
    "save_path = '../processed/data_preprocessed.pkl'\n",
    "\n",
    "for i in range(len(subject_list)):\n",
    "    all_data_raw[group_name[i]] = {}\n",
    "    all_data_epoch[group_name[i]] = {}\n",
    "    for j in range(len(subject_list[i])):\n",
    "        subname = subject_list[i][j][0:2]\n",
    "        all_data_raw[group_name[i]][subname] = {}\n",
    "\n",
    "        # Get Paths of all condition of current subject\n",
    "        conds = os.listdir(os.path.join(data_pth, folders[i], subject_list[i][j]))\n",
    "        conds_of_interest = [k for k in conds if any([k.startswith('PL'), k.startswith('PS')]) \n",
    "                            if not k.startswith('.') if k.endswith('.vhdr')]\n",
    "        filepaths = [os.path.join(data_pth, folders[i], subject_list[i][j], k) for k in conds_of_interest]\n",
    "        filepaths.sort()\n",
    "        \n",
    "        # Initialize Logging\n",
    "        logger = custom_logger(os.path.dirname(save_path) + '/logs/' + subject_list[i][j] + '.log')\n",
    "        \n",
    "        # Raws\n",
    "        raws = [load_prepare_data(filepath, rereference, filtfreq, perform_ICA=perform_ICA, logger=logger,\n",
    "                rm_bad_chans=rm_bad_chans, n_jobs=n_jobs) for filepath in filepaths]\n",
    "        # Epochs\n",
    "        epocheds = [epoch_clean(raw, baseline, trial_time, onoff, art_thresh, srate, \n",
    "                    round_to, triglens, triglabel, logger=logger, stim_names=stimulus, csd=csd,\n",
    "                    use_ransac=use_ransac) for raw, triglabel, stimulus in zip(raws, triglabels, stimuli)]\n",
    "        epochs = concatenate_epochs(epocheds)\n",
    "\n",
    "\n",
    "        all_data_raw[group_name[i]][subname][file_codes[0]] = raws[0]\n",
    "        all_data_raw[group_name[i]][subname][file_codes[1]] = raws[1]\n",
    "        all_data_epoch[group_name[i]][subname] = epochs\n",
    "\n",
    "with open(save_path, 'wb') as f:\n",
    "    pkl.dump([all_data_raw, all_data_epoch], f)\n",
    "    print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ab6a524f8fdefa2fba1a0ab7407e8dbd386bc97b991bfb50d01a11f6cd0d5f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('eeg_cl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
